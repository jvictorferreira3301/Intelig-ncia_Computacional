{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2\n",
    "\n",
    "Para a parte 2 do projeto escolhemos o dataset `credit_data.csv` (https://www.kaggle.com/datasets/laotse/credit-risk-dataset [adaptado]) que contém colunas que simulam dados de agências de crédito. Os atributos são as colunas `income` `age` `loan` e a classe é a coluna `default`, classificando quem paga os empréstims com `1` e quem não paga com `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise inicial, Tratamento e Pré-processamento dos dados (Deliverable 3)\n",
    "\n",
    "Primeiramente, realizamos uma análise primária no dataset escolhido para a parte 2 utilizando a biblioteca `pandas` para reconhecer nossos `atributos` e `classes`. Através da função `describe` evidenciamos as estatísticas e vemos alguns valores inconsistentes que posteriormente são tratados para não afetar negativamente nosso modelo com dados incongruentes. Exemplo: idade negativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express  as px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,  classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>45331.600018</td>\n",
       "      <td>40.807559</td>\n",
       "      <td>4444.369695</td>\n",
       "      <td>0.141500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>577.494589</td>\n",
       "      <td>14326.327119</td>\n",
       "      <td>13.624469</td>\n",
       "      <td>3045.410024</td>\n",
       "      <td>0.348624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20014.489470</td>\n",
       "      <td>-52.423280</td>\n",
       "      <td>1.377630</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>500.750000</td>\n",
       "      <td>32796.459717</td>\n",
       "      <td>28.990415</td>\n",
       "      <td>1939.708847</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>45789.117313</td>\n",
       "      <td>41.317159</td>\n",
       "      <td>3974.719419</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1500.250000</td>\n",
       "      <td>57791.281668</td>\n",
       "      <td>52.587040</td>\n",
       "      <td>6432.410625</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>69995.685578</td>\n",
       "      <td>63.971796</td>\n",
       "      <td>13766.051239</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          clientid        income          age          loan      default\n",
       "count  2000.000000   2000.000000  1997.000000   2000.000000  2000.000000\n",
       "mean   1000.500000  45331.600018    40.807559   4444.369695     0.141500\n",
       "std     577.494589  14326.327119    13.624469   3045.410024     0.348624\n",
       "min       1.000000  20014.489470   -52.423280      1.377630     0.000000\n",
       "25%     500.750000  32796.459717    28.990415   1939.708847     0.000000\n",
       "50%    1000.500000  45789.117313    41.317159   3974.719419     0.000000\n",
       "75%    1500.250000  57791.281668    52.587040   6432.410625     0.000000\n",
       "max    2000.000000  69995.685578    63.971796  13766.051239     1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_credit = pd.read_csv(\"datasets/credit_data.csv\")\n",
    "base_credit.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos trecho abaixo, apagamos somente os dados incorretos e preenchemos as lacunas com a média do resto dos dados. Fizemos o mesmo para linhas com dados faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit3 = base_credit.drop(base_credit[base_credit['age']< 0].index) # outro método é preencher-los manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Média com os valores inconsistentes: ',base_credit['age'].mean()) \n",
    "print('Média com valores inconsistentes removidos: ',base_credit3['age'].mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.loc[base_credit['age'] < 0, 'age'] = 40.92 # Preenchimento dos valores inconsistentes com a média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit.loc[pd.isnull(base_credit['age'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_credit['age'].fillna(base_credit['age'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão entre Previsores e Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_credit = base_credit.iloc[:, 1:4].values\n",
    "X_credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_credit = base_credit.iloc[:, 4].values\n",
    "y_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padronizaçao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo são realizadas algumas etapas de pré-processamento, essas etapas são comumente usadas para normalizar os dados, garantindo que eles estejam na mesma escala antes de serem usados em algoritmos de aprendizado de máquina. A padronização é uma técnica que transforma os dados de forma que eles tenham média zero e desvio padrão igual a um. Isso pode ser útil para algoritmos que assumem que os dados estão normalmente distribuídos e têm a mesma escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_credit = StandardScaler()\n",
    "X_credit = scaler_credit.fit_transform(X_credit)\n",
    "X_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão entre treinamento e teste (Deliverable 3)\n",
    "\n",
    "Neste trecho de código, está sendo realizado o particionamento dos dados em conjuntos de treinamento e teste usando a função `train_test_split`. Sendo 70% do dataset para treino e 30% para teste.\n",
    "\n",
    "Esse particionamento dos dados é uma etapa importante para garantir que o modelo seja avaliado corretamente e que possa generalizar bem para novos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_credit_train, X_credit_teste, y_credit_train, y_credit_teste = train_test_split(X_credit, y_credit, test_size = 0.30, random_state=0)\n",
    "X_credit_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeiro modelo: Naive Beans\n",
    "\n",
    "Antes de treinar o modelo vamos verificar quais os melhores hipeparâmetros para o algoritimo SVM através da classe `GridSearchCV` da biblioteca `scikitlearn`. O GridSearchCV é uma técnica popular em aprendizado de máquina usada para encontrar os melhores hiperparâmetros para um modelo, funciona através da criação de um \"grid\" de hiperparâmetros possíveis e testa todas as combinações possíveis desses hiperparâmetros, usando validação cruzada para avaliar o desempenho de cada combinação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Cria uma instância do classificador Naive Bayes com a distribuição Gaussiana (GaussianNB)\n",
    "naive_credit_data = GaussianNB() \n",
    "\n",
    "# Define os hiperparâmetros para testar\n",
    "param_grid = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=200)\n",
    "}\n",
    "\n",
    "# Cria o objeto GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=naive_credit_data, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Treina o modelo com o Grid Search\n",
    "grid_search.fit(X_credit_train, y_credit_train)\n",
    "\n",
    "# Obtem os melhores hiperparâmetros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Imprime os melhores hiperparâmetros\n",
    "print(\"Melhores hiperparâmetros encontrados:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "naive_credit_data = GaussianNB(var_smoothing=8.504489341802669e-05) # Cria uma instância do classificador Naive Bayes com a distribuição Gaussiana (GaussianNB)\n",
    "naive_credit_data.fit(X_credit_train, y_credit_train) # Treina o modelo Naive Bayes com os dados de treinamento padronizados e seus rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_credit_data = GaussianNB(var_smoothing=8.504489341802669e-05) # Cria uma instância do modelo NB com o valor encontrado como melhor para hiperparâmetro var_smoothing.\n",
    "naive_credit_data.fit(X_credit_train, y_credit_train) # Treina o modelo \n",
    "NB_predict = naive_credit_data.predict(X_credit_teste) # Faz previsões usando o modelo Naive Bayes treinado nos dados de teste e armazena na variavel predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_credit_teste  # Rótulos verdadeiros\n",
    "y_pred = NB_predict  # Previsões do modelo\n",
    "\n",
    "# Calcula a matriz de confusão\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plota a matriz de confusão como um mapa de calor (heatmap)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sn.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Previsão')\n",
    "plt.ylabel('Rotulo Verdadeiro')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       524\n",
      "           1       0.84      0.61      0.70        76\n",
      "\n",
      "    accuracy                           0.94       600\n",
      "   macro avg       0.89      0.79      0.83       600\n",
      "weighted avg       0.93      0.94      0.93       600\n",
      "\n",
      "0.935\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_credit_teste, NB_predict))\n",
    "print(accuracy_score(y_credit_teste, NB_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segundo modelo: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Cria uma instância do classificador Decision Tree\n",
    "tree_credit = DecisionTreeClassifier()\n",
    "\n",
    "# Define os hiperparâmetros para testar\n",
    "param_grid = {\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "# Cria o objeto GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=tree_credit, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Treina o modelo com o Grid Search\n",
    "grid_search.fit(X_credit_train, y_credit_train)\n",
    "\n",
    "# Obtem os melhores hiperparâmetros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Imprime os melhores hiperparâmetros\n",
    "print(\"Melhores hiperparâmetros encontrados:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_credit = DecisionTreeClassifier(criterion='entropy', random_state=0, min_samples_split=2, min_samples_leaf=1, max_depth=10)\n",
    "tree_credit.fit(X_credit_train, y_credit_train)\n",
    "tree_predict = tree_credit.predict(X_credit_teste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_credit_teste # Rótulos verdadeiros\n",
    "y_pred = tree_predict  # Previsões do modelo\n",
    "\n",
    "# Calcula a matriz de confusão\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plota a matriz de confusão como um mapa de calor (heatmap)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sn.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Previsão')\n",
    "plt.ylabel('Rotulo Verdadeiro')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "previsores = ['income', 'age', 'loan']\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (10,10))\n",
    "tree.plot_tree(tree_credit, feature_names=previsores, class_names=['0','1'], filled=True);\n",
    "fig.savefig('tree_credit.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       524\n",
      "           1       0.92      0.95      0.94        76\n",
      "\n",
      "    accuracy                           0.98       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.98      0.98      0.98       600\n",
      "\n",
      "0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_credit_teste, tree_predict))\n",
    "print(accuracy_score(y_credit_teste, tree_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terceiro modelo: SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Cria uma instância do classificador SVM\n",
    "svm_credit = svm.SVC()\n",
    "\n",
    "# Define os hiperparâmetros para testar\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Cria o objeto GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=svm_credit, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Treina o modelo com o Grid Search\n",
    "grid_search.fit(X_credit_train, y_credit_train)\n",
    "\n",
    "# Obtem os melhores hiperparâmetros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Imprime os melhores hiperparâmetros\n",
    "print(\"Melhores hiperparâmetros encontrados:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm_credit = svm.SVC(C=100, gamma='auto', kernel='rbf')\n",
    "svm_credit.fit(X_credit_train, y_credit_train)\n",
    "svm_predict = svm_credit.predict(X_credit_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_credit_teste # Rótulos verdadeiros\n",
    "y_pred = svm_predict  # Previsões do modelo\n",
    "\n",
    "# Calcula a matriz de confusão\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plota a matriz de confusão como um mapa de calor (heatmap)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sn.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Previsão')\n",
    "plt.ylabel('Rotulo Verdadeiro')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       524\n",
      "           1       0.99      0.91      0.95        76\n",
      "\n",
      "    accuracy                           0.99       600\n",
      "   macro avg       0.99      0.95      0.97       600\n",
      "weighted avg       0.99      0.99      0.99       600\n",
      "\n",
      "0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_credit_teste, svm_predict))\n",
    "print(accuracy_score(y_credit_teste, svm_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão\n",
    "Obtivemos resultados positivos acima dos 90% de acurácia nos 3 modelos testados, ficando mais ou menos empatado entre os modelos Decision Tree e SVM, então abaixo iremos analisar as estatísticas obtidas nos dois modelos e decidir qual o melhor:\n",
    "\n",
    "### Acurácia (Accuracy):\n",
    "\n",
    "- Decision Tree: 98%\n",
    "- SVM: 99%\n",
    "\n",
    "O modelo SVM obteve uma acurácia ligeiramente maior em comparação com a árvore de decisão. Isso significa que o SVM classifica corretamente uma maior proporção de exemplos em comparação com a árvore de decisão.\n",
    "\n",
    "### Precisão (Precision):\n",
    "\n",
    "- Para a classe 0 (negativa):\n",
    "Decision Tree: 99%\n",
    "SVM: 99%\n",
    "- Para a classe 1 (positiva):\n",
    "Decision Tree: 92%\n",
    "SVM: 99%\n",
    "\n",
    "O SVM obteve uma precisão ligeiramente maior para a classe 1 (positiva), o que significa que o SVM comete menos falsos positivos em comparação com a árvore de decisão.\n",
    "\n",
    "### Revocação (Recall):\n",
    "\n",
    "- Para a classe 0 (negativa):\n",
    "Decision Tree: 99%\n",
    "SVM: 100%\n",
    "- Para a classe 1 (positiva):\n",
    "Decision Tree: 95%\n",
    "SVM: 91%\n",
    "\n",
    "A árvore de decisão obteve uma revocação ligeiramente maior para a classe 1 (positiva), o que significa que a árvore de decisão identifica corretamente uma maior proporção de exemplos positivos em comparação com o SVM.\n",
    "\n",
    "### F1-Score:\n",
    "\n",
    "- Para a classe 0 (negativa):\n",
    "Decision Tree: 99%\n",
    "SVM: 99%\n",
    "- Para a classe 1 (positiva):\n",
    "Decision Tree: 94%\n",
    "SVM: 95%\n",
    "\n",
    "O SVM obteve um F1-score ligeiramente maior para a classe 1 (positiva), o que representa um equilíbrio entre precisão e revocação.\n",
    "\n",
    "\n",
    "Em resumo, o SVM parece ter um desempenho ligeiramente melhor em termos de acurácia geral, enquanto a árvore de decisão obteve um desempenho melhor em termos de revocação para a classe positiva. A escolha entre esses modelos dependerá das necessidades específicas do problema e das métricas de avaliação prioritárias.\n",
    "\n",
    "# Sample Complexity (Deliverable 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
